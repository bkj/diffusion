# diffusion

From 

This branch contains extentions on the exploration of graph laplacian diffusion as a method to do various classification tasks, given some set of vector features. One method for computing diffusion follows [this](https://arxiv.org/pdf/1811.10907.pdf) paper. Reasonably strong performance is shown for image and time series classification tasks with respect to other relatively state of the art methods. 

Furthermore, we explore using the diffusion manifold as a starting-point for active learning. We "actively learn" by obtaining labels for only the k-medioid points on the manifold, and using 1-NN medioid points to classify the rest. We extend this "active learning" paradigm in scratch/active-learning-extention.py where the manifold is computed using the graph laplacian, and K-medioids is used to obtain the initial labels, and we "query" the labels for points which are furthest from any medioid point ('active-iterated sampling'), which provides slightly better performance in some specialized cases. 

### diffusion.py 
Contains two methods for computing diffusion on a manifold generated by some distance graph. 
- TruncatedDiffusion() is a computationally optimized method based on [this paper](https://arxiv.org/pdf/1811.10907.pdf) which generates a sparse graph representation where only the k-cosine nearest neibors are considered for diffusion of a given data.
- VanillaDiffusion() computes a graph Laplacian for diffusion between all elements of the graph without any real optimization.

### classifier.py 
Demonstrates a comparison between ResNet, SVC, and Diffusion method explored here on image classifcation on CIFAR 10. 

### helpers.py 
contains some helpful general functions

### scratch/ includes several experiments
active-learning-performance.py represents the most comprehensive summary of the work in this direction on time series classification. We explore the cartesian product of classifiers (SVM, 1-NN) on distance metrics(diffusion "distance", dtw-distance, cosine distance, and euclidian distance), with various sampling strategies in the active learning sense (Random, K-medioid, K-medioid with iterated sampling). Results vis-a-vis some other SOTA time series classification is shown below (obtained from [this benchmark](https://github.com/cauchyturing/UCR_Time_Series_Classification_Deep_Learning_Baseline)).
![](https://github.com/cfld/diffusion/blob/eab/results/ucr/SOTA_categories.png)

manifold_vector_properties.py investigates if there is a clear relationship between the cosine distances and "distance" in diffusion space for various datasets.
